
\chapter*{Introduction}
\label{sec:intro}
We are in the era of autonomous driving. Vehicles are becoming endowed with more and more sensors, whose signals are processed to navigate in the surrounding.
As humans use mostly vision among their senses to perceive and act, the cars, the robots or in general the machines could heavily rely on image data to interact with the environment.
Computer Vision aims at extracting meaningful information from images such as the class the subject belongs to, the action happening in the scene or the 3D model of the environment, while Robotics aims at designing robots, or autonomous machines, and at deploying them in the real world.
Thanks to the joint efforts of these two communities many advancements have been achieved in different aspect enabling the autonomous driving.

One of the key aspect needed to navigate through an environment is the knowledge of the map of the environment itself. 
While many Simultaneous Localization and Mapping algorithms have been proposed to navigate through an environment without the map, in real world scenario we need to decouple these aspect in order to achieve both robustness and speed.
If a map of the environment is known, the robot is able to localize itself and navigate through them following a path defined by the user.

In Robotics and Computer Vision, visual mapping, or 3D reconstruction, is a long standing field of research: it aims at building a 3D model of environment assuming that the pose of the camera is known from external calibration, for instance from explicit measurements, from telemetry or self-calibration algorithms.

\section{Motivation}
In the last decade, many approaches have been proposed that differs from various aspects, e.g., initialization, optimization procedure, model representation.


automatic
continuous mesh
large-scale
incremental






\section{Thesis contributions}
\section{Thesis outline}