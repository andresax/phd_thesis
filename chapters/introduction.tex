
\chapter*{Introduction}
\label{sec:intro}
We are in the era of autonomous driving. Vehicles are becoming endowed with more and more sensors, whose signals are processed to navigate in the surrounding.
As humans use mostly vision among their senses to perceive and act, the cars, the robots or in general the machines could heavily rely on image data to interact with the environment.
Computer Vision aims at extracting meaningful information from images such as the class the subject belongs to, the action happening in the scene or the 3D model of the environment, while Robotics aims at designing robots, or autonomous machines, and at deploying them in the real world.
Thanks to the joint efforts of these two communities many advancements have been achieved in different aspect enabling the autonomous driving.

One of the key aspect needed to navigate through an environment is the knowledge of the map of the environment itself. 
While many Simultaneous Localization and Mapping algorithms have been proposed to navigate through an environment without the map, in real world scenario we need to decouple these aspects in order to achieve both robustness and speed.
In principle, if a map of the environment is known, the robot is able to localize itself and navigate through them following a path defined by the user.

In Robotics and Computer Vision, visual mapping, or 3D reconstruction, is a long standing field of research: it aims at building a 3D model of environment assuming that the pose of the camera is known from external calibration, for instance from explicit measurements, from telemetry or self-calibration algorithms.
%Robotics and Computer Vision pursue different aims 
% Mapping from images is an ill-posed problem since from 2D data the aim is to recover a 3D structure.

\section{Motivation}
In the last decade, many mapping approaches have been proposed; they differ from various aspects, e.g., initialization, optimization procedure, 3D model representation.

dicotomia robotics e computer vision

The model of the scene can be represented in very different ways: point, 3D patches, volumes or surfaces.
Points are adopted when the computational time is the limited resource, for instance, in Robotics when Simultaneous Localization and Mapping, and 3D patches requires a highly textured scenes; these  approaches results
The simpler but very popular in the Robotics community 

Some algorithms requires an initialization also known as convex hull, which needs the knowledge of the silhouette of the objects, which  is not a realistic assumption in real world scenarios; other algorithms are able to cope with general scenes but the pipeline is not fully automatic






automatic
continuous mesh
large-scale
incremental
manifold





\section{Thesis contributions}
In this thesis we overcome the issue described thus far and we started to build a bridge between Robotics, and mesh-based Multi-View Stereo.
We propose the first automatic and incremental pipeline able to build a dense, scalable and manifold mesh.
The mesh representation is necessary to reconstruct  large-scale scenes and, by keeping the manifold property valid along the whole processing, we are also able to design a completely automatic pipeline.

The building blocks of our pipeline are essentially two: incremental reconstruction from Sparse Points and incremental refinement.
The former estimates a  manifold mesh from camera poses, sparse point clouds and camera-to-point viewing rays, e.g., the output of a Structure from Motion algorithm.
The algorithm relies on a volumetric representation, in particular the Delaunay triangulation; each tetrahedron is voted consistently with the rays ant the manifold mesh is extracted as the boundary between those which receive high votes (free space) and those traversed by non or few rays (matter).
We investigated which kind of 3D points are suitable for Delaunay Triangulation for 3D reconstruction; since 3D points on the real-world edges lead the edges of Delaunay tetrahedra to lay on them, we proved that, when the output is a video, 2D edge-points on the images are the most convenient feature to be reconstructed in 3D.
We also proposed a new voting scheme which improves the accuracy of the reconstruction with respect to the state of the art, and we now efficiently handle moving point inside the triangulation.
In the incremental refinement we propse a novel approach to build a dense and detailed map of the environment.
While all of the Multi-View Stereo algorithm process all the images  at the same time, and Robotics dense SLAM algorithms works in small environment, we reconstruct small and large scenes incrementally. 
We evolve photometrically the part of the scene yet estimated by the previous step, once the refinement is over, we merge it with the new mesh from the sparse point cloud with a novel merging algorithm which is able to keep the manifold property valid.


We 






\section{Thesis outline}










